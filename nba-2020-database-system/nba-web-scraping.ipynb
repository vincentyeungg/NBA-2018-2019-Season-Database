{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Obtaining data for 'Teams' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - create directory to store downloaded files, obtain data for each time, and save to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory \"data\" cannot be created\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "year = 2019\n",
    "base_url = \"https://www.basketball-reference.com\"\n",
    "url = f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\"\n",
    "\n",
    "data = requests.get(url)\n",
    "\n",
    "# create directory\n",
    "dir_name = 'data'\n",
    "try:\n",
    "    os.makedirs(dir_name)\n",
    "except OSError as error:\n",
    "    print(f'Directory \"{dir_name}\" cannot be created')\n",
    "\n",
    "# download data and save into html file for data parsing, instead of downloading the entire page each time\n",
    "with open(f\"data/{year}.html\", \"w+\", encoding=\"cp437\", errors='ignore') as f:\n",
    "    f.write(data.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(f\"data/{year}.html\") as f:\n",
    "    # read the file and store the data as a string obj\n",
    "    page = f.read()\n",
    "\n",
    "# initialize soup object to parse html data\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "# get the abbreviated team names and store into a list (some abbreviated names are different on this site)\n",
    "nba_team_pages = []\n",
    "\n",
    "# find the appropriate tables with the team stats for every team in the NBA\n",
    "eastern_conf_table = soup.find(id=\"confs_standings_E\")\n",
    "western_conf_table = soup.find(id=\"confs_standings_W\")\n",
    "\n",
    "# eastern conference teams\n",
    "for a in eastern_conf_table.find_all('a'):\n",
    "    nba_team_pages.append(a['href'])\n",
    "\n",
    "# western conference teams\n",
    "for a in western_conf_table.find_all('a'):\n",
    "    nba_team_pages.append(a['href'])\n",
    "\n",
    "# team abbrs\n",
    "team_abbrs = []\n",
    "\n",
    "for abbr in nba_team_pages:\n",
    "    team_abbrs.append(abbr.split('/')[2])\n",
    "\n",
    "# at this step, you will have a list of abbreviated team names that matches the format the site uses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory \"data\\teams\" cannot be created\n"
     ]
    }
   ],
   "source": [
    "# from selenium import webdriver\n",
    "# import time\n",
    "\n",
    "# create directory\n",
    "parent_dir = dir_name\n",
    "dir_name = os.path.join(parent_dir, 'teams')\n",
    "\n",
    "try:\n",
    "    os.makedirs(dir_name)\n",
    "except OSError as error:\n",
    "    print(f'Directory \"{dir_name}\" cannot be created')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through each page and save them to their corresponding html files\n",
    "for abbr_name in team_abbrs:\n",
    "    # use Selenium here to allow page content that require Javascript to be rendered\n",
    "\n",
    "    url = f\"https://www.basketball-reference.com/teams/{abbr_name}/{year}.html\"\n",
    "\n",
    "    html_data = requests.get(url)\n",
    "\n",
    "    # download data and save into html file for data parsing, instead of downloading the entire page each time\n",
    "    with open(f\"{dir_name}/{abbr_name}.html\", \"w+\", encoding=\"cp437\", errors='ignore') as f:\n",
    "        f.write(html_data.text)\n",
    "\n",
    "# at this step, you will have the html files of all the individual teams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the names to match directory order\n",
    "team_abbrs.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "teams_df = pd.DataFrame(\n",
    "    columns=['Name', 'Abbreviated Name', 'Arena', 'Wins', 'Losses', 'W-L'])\n",
    "\n",
    "for idx, team in enumerate(team_abbrs, start=1):\n",
    "    # each team should have a name, abbr name, wins, losses, location\n",
    "    with open(f'data/teams/{team}.html', encoding=\"cp437\", errors='ignore') as f:\n",
    "        page = f.read()\n",
    "\n",
    "        # initialize soup object to parse html data\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        # team name\n",
    "        team_name = soup.find(id=\"info\").find_all('span')[1].extract().text\n",
    "\n",
    "        # wins/losses\n",
    "        wins_and_losses = soup.find(id=\"info\").select_one('div[data-template=\"Partials/Teams/Summary\"]').find(\n",
    "            'p').extract().text.replace(\" \", \"\").replace(\"\\n\", \"\").split(\",\")[0].split(\":\")[1]\n",
    "        wins = wins_and_losses.split(\"-\")[0]\n",
    "        losses = wins_and_losses.split(\"-\")[1]\n",
    "\n",
    "        # location i.e. arena\n",
    "        # filter string to find the arena name\n",
    "        locations = soup.find(id=\"info\").select_one(\n",
    "            'div[data-template=\"Partials/Teams/Summary\"]').find_all('p')\n",
    "        pattern = 'Attendance'\n",
    "        location = None\n",
    "        match = None\n",
    "\n",
    "        # find the tag with the arena\n",
    "        for loc in locations:\n",
    "            match = (re.search(pattern, loc.text))\n",
    "            if match:\n",
    "                location = loc.text\n",
    "                break\n",
    "\n",
    "        # # obtain only the arena name, and filter further\n",
    "        # location = location[:match.start()].replace(\"\\n\", \"\").replace(\" \", \"\").split(\":\")[-1]\n",
    "        location = location[:match.start()].replace(\n",
    "            \"\\n\", \"\").split(\":\")[-1].strip()\n",
    "\n",
    "        teams_df.loc[idx] = [team_name, team,\n",
    "                             location, wins, losses, wins_and_losses]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_names = list(teams_df.loc[:, 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the wins and lossees columns from strings to ints\n",
    "teams_df['Wins'] = pd.to_numeric(teams_df['Wins'])\n",
    "teams_df['Losses'] = pd.to_numeric(teams_df['Losses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory \"csv_files\" cannot be created\n"
     ]
    }
   ],
   "source": [
    "# create directory\n",
    "dir_name = 'csv_files'\n",
    "\n",
    "try:\n",
    "    os.makedirs(dir_name)\n",
    "except OSError as error:\n",
    "    print(f'Directory \"{dir_name}\" cannot be created')\n",
    "\n",
    "teams_df.to_csv('csv_files/teams.csv', header=teams_df.columns, index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Obtain team stats data for each team, filter data, convert to dataframe, and save to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import Comment\n",
    "\n",
    "teams_stats_df = pd.DataFrame(\n",
    "    columns=[\n",
    "        # \"Name\",\n",
    "        \"Field Goals\",\n",
    "        \"Field Goals Attempted\",\n",
    "        \"Field Goal %\",\n",
    "        \"3-Point Field Goals\",\n",
    "        \"3-Point Field Goals Attempted\",\n",
    "        \"3-Point Field Goal %\",\n",
    "        \"2-Point Field Goals\",\n",
    "        \"2-Point Field Goals Attempted\",\n",
    "        \"2-Point Field Goal %\",\n",
    "        \"Free Throws\",\n",
    "        \"Free Throws Attempted\",\n",
    "        \"Free Throw %\",\n",
    "        \"Offensive Rebounds\",\n",
    "        \"Defensive Rebounds\",\n",
    "        \"Total Rebounds\",\n",
    "        \"Assists\",\n",
    "        \"Steals\",\n",
    "        \"Blocks\",\n",
    "        \"Turnovers\",\n",
    "        \"Personal Fouls\",\n",
    "        \"Points\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "for idx, team in enumerate(team_abbrs, start=1):\n",
    "    # each team should have a name, abbr name, wins, losses, location\n",
    "    with open(f'data/teams/{team}.html', encoding=\"cp437\", errors='ignore') as f:\n",
    "        page = f.read()\n",
    "\n",
    "        # initialize soup object to parse html data\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        comments = soup.find_all(string=lambda text: isinstance(text, Comment))\n",
    "\n",
    "        # filter for the commented tables, and returns a list of tables and their contents\n",
    "        table_comments = list(\n",
    "            filter(lambda comment: 'table' in str(comment), comments))\n",
    "\n",
    "        # obtain the team stats table\n",
    "        team_table = []\n",
    "        for comment in table_comments:\n",
    "            try:\n",
    "                team_table.append(pd.read_html(\n",
    "                    comment, attrs={'id': 'team_and_opponent'})[0])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        team_df = team_table[0]\n",
    "        \n",
    "        # filter the data, replace 'nan' with 0 values\n",
    "        team_df = team_df.fillna(0)\n",
    "\n",
    "        # filter for only the first columns where the target data is\n",
    "        team_stats_dict = dict(team_df.iloc[1])\n",
    "\n",
    "        # removing columns that don't need\n",
    "        team_stats_list = [\n",
    "            stat\n",
    "            for (category, stat) in team_stats_dict.items()\n",
    "            if category not in [\"Unnamed: 0\", \"G\", \"MP\"]\n",
    "        ]\n",
    "        \n",
    "        # add to dataframe\n",
    "        teams_stats_df.loc[idx] = (team_stats_list)\n",
    "\n",
    "# append the team names as a column in the table\n",
    "teams_stats_df['Name'] = team_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to adjust column data types from objects to floats\n",
    "\n",
    "# iterate through the column names, and change all column types to float64\n",
    "for col in list(teams_stats_df.keys()):\n",
    "    if col != 'Name':\n",
    "        teams_stats_df = teams_stats_df.astype({col: float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory \"csv_files\" cannot be created\n"
     ]
    }
   ],
   "source": [
    "# create directory\n",
    "dir_name = 'csv_files'\n",
    "\n",
    "try:\n",
    "    os.makedirs(dir_name)\n",
    "except OSError as error:\n",
    "    print(f'Directory \"{dir_name}\" cannot be created')\n",
    "\n",
    "teams_stats_df.to_csv('csv_files/teams_stats.csv', header=teams_stats_df.columns, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Obtain player basic info i.e. Name, Date of Birth, Position, Team and save to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df = pd.DataFrame(\n",
    "    columns=[\n",
    "        'Name',\n",
    "        'Date of Birth',\n",
    "        'Position',\n",
    "        'Team'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# for each team, it contains data of their roster and their stats\n",
    "# each player name contains a link to their profile page with the necessary data\n",
    "for team in team_abbrs:\n",
    "    with open(f'data/teams/{team}.html', encoding=\"cp437\", errors='ignore') as f:\n",
    "        page = f.read()\n",
    "\n",
    "        # initialize soup object to parse html data\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "        \n",
    "        # for each time, find a list of the players and their <a> tag pointing to their profile\n",
    "        players_stats_list = soup.find('table', id=\"per_game\").find_all('a')\n",
    "        \n",
    "        # filter the list\n",
    "        players_stats_links = [ a for a in players_stats_list if '/gamelog/' not in str(a) ]\n",
    "        \n",
    "        # obtain only the links, not the entire <a> tag\n",
    "        players_stats_links = [ str(href).split('\"')[1] for href in players_stats_links ]\n",
    "        \n",
    "        # obtain the team name\n",
    "        team_name = soup.find(id=\"info\").find_all('span')[1].extract().text\n",
    "        \n",
    "        for url in players_stats_links:\n",
    "            # go to url of specific player\n",
    "            html_data = requests.get(base_url + url)\n",
    "            \n",
    "            # get the html content of the url\n",
    "            html = html_data.text\n",
    "            \n",
    "            # need to extract Name, Age, Position, Team\n",
    "            # initialize soup object to parse html data\n",
    "            soup = BeautifulSoup(html, \"html.parser\")\n",
    "            info = soup.find(id='meta').find('div', class_=lambda class_name: class_name != 'media-item')\n",
    "            \n",
    "            # name\n",
    "            name = info.find('h1').find('span').text\n",
    "            \n",
    "            # date of birth\n",
    "            dob = info.find('span', id=lambda _id: _id == 'necro-birth').text.replace('\\n', \"\").split(',')\n",
    "            dob = \" \".join([element.strip() for element in dob])\n",
    "            dob_obj = datetime.strptime(dob, \"%B %d %Y\")\n",
    "            dob = str(dob_obj).split(' ')[0]\n",
    "            \n",
    "            # position\n",
    "            position_element = [p for p in info.find_all('p') if 'Position' in str(p)]\n",
    "            position = position_element[0].text.replace(\"\\n\", \"\").strip().replace(\"â–ª\", \"\").replace(\"         \", \",\").split(\", \")[0].split(\":\")[1].strip()    \n",
    "            \n",
    "            # add it as a new row into players_df at the end\n",
    "            players_df.loc[players_df.shape[0]] = [name, dob, position, team_name]\n",
    "\n",
    "\n",
    "# players_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change type of dob to datetime64\n",
    "players_df['Date of Birth'] = pd.to_datetime(players_df['Date of Birth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory \"csv_files\" cannot be created\n"
     ]
    }
   ],
   "source": [
    "# adjust indexing on current data frame\n",
    "players_df.index += 1\n",
    "\n",
    "# save it to a csv file\n",
    "\n",
    "# create directory\n",
    "dir_name = 'csv_files'\n",
    "\n",
    "try:\n",
    "    os.makedirs(dir_name)\n",
    "except OSError as error:\n",
    "    print(f'Directory \"{dir_name}\" cannot be created')\n",
    "\n",
    "players_df.to_csv('csv_files/players.csv', header=players_df.columns, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Obtain player stats and save to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_stats_df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Name\",\n",
    "        \"Minutes Played\",\n",
    "        \"Field Goals\",\n",
    "        \"Field Goals Attempted\",\n",
    "        \"Field Goal %\",\n",
    "        \"3-Point Field Goals\",\n",
    "        \"3-Point Field Goals Attempted\",\n",
    "        \"3-Point Field Goal %\",\n",
    "        \"2-Point Field Goals\",\n",
    "        \"2-Point Field Goals Attempted\",\n",
    "        \"2-Point Field Goal %\",\n",
    "        \"Effective Field Goal %\",\n",
    "        \"Free Throws\",\n",
    "        \"Free Throws Attempted\",\n",
    "        \"Free Throw %\",\n",
    "        \"Offensive Rebounds\",\n",
    "        \"Defensive Rebounds\",\n",
    "        \"Total Rebounds\",\n",
    "        \"Assists\",\n",
    "        \"Steals\",\n",
    "        \"Blocks\",\n",
    "        \"Turnovers\",\n",
    "        \"Personal Fouls\",\n",
    "        \"Points\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "for team in team_abbrs:\n",
    "    # for each team, it contains data of their roster and their stats\n",
    "    with open(f'data/teams/{team}.html', encoding=\"cp437\", errors='ignore') as f:\n",
    "        page = f.read()\n",
    "\n",
    "        # initialize soup object to parse html data\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        # find table with the per game stats of the players\n",
    "        players_stats_table = soup.find('table', id=\"per_game\")\n",
    "\n",
    "        # convert table to pandas dataframe\n",
    "        stats_df = pd.read_html(str(players_stats_table))[0]\n",
    "\n",
    "        # drop rk, age, g, gs columns\n",
    "        stats_df = stats_df.drop([\"Rk\", \"Age\", \"G\", \"GS\"], axis=1)\n",
    "\n",
    "        # filter the data, replace 'nan' with 0 values\n",
    "        stats_df = stats_df.fillna(0)\n",
    "\n",
    "        stats_df = stats_df.values.tolist()\n",
    "\n",
    "        # insert the stats rows for each player into the dataframe\n",
    "        for stats_row in stats_df:\n",
    "            players_stats_df.loc[players_stats_df.shape[0]] = stats_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to adjust column data types from objects to floats\n",
    "\n",
    "# iterate through the column names, and change all column types to float64\n",
    "for col in list(players_stats_df.keys()):\n",
    "    if col != 'Name':\n",
    "        players_stats_df = players_stats_df.astype({col: float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory \"csv_files\" cannot be created\n"
     ]
    }
   ],
   "source": [
    "# adjust indexing on current data frame\n",
    "players_stats_df.index += 1\n",
    "\n",
    "# save it to a csv file\n",
    "\n",
    "# create directory\n",
    "dir_name = 'csv_files'\n",
    "\n",
    "try:\n",
    "    os.makedirs(dir_name)\n",
    "except OSError as error:\n",
    "    print(f'Directory \"{dir_name}\" cannot be created')\n",
    "\n",
    "players_stats_df.to_csv('csv_files/players_stats.csv', header=players_stats_df.columns, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Obtain coach details and save to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "coach_links = []\n",
    "team_name = []\n",
    "\n",
    "# obtain the links for the coaches\n",
    "for team in team_abbrs:\n",
    "    # for each team, it contains link to data of their coach\n",
    "    with open(f'data/teams/{team}.html', encoding=\"cp437\", errors='ignore') as f:\n",
    "        page = f.read()\n",
    "\n",
    "        # initialize soup object to parse html data\n",
    "        soup = BeautifulSoup(page, \"html.parser\")\n",
    "\n",
    "        # find the link for the coach details\n",
    "        info = soup.find(id='meta').find(\n",
    "            'div', {'data-template': \"Partials/Teams/Summary\"})\n",
    "\n",
    "        # obtain the href of the coach link tag\n",
    "        coach_link_tag = [p for p in info.find_all(\n",
    "            'p') if 'Coach' in str(p)][0]\n",
    "        coach_link = str(coach_link_tag.find('a')['href'])\n",
    "\n",
    "        # add it to list of coach links\n",
    "        coach_links.append(coach_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "coach_df = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Name\",\n",
    "        \"Date of Birth\",\n",
    "        \"Team\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "for team, url, team_name in zip(team_abbrs, coach_links, team_names):\n",
    "    html_data = requests.get(base_url + url)\n",
    "\n",
    "    # get the html content of the url\n",
    "    html = html_data.text\n",
    "\n",
    "    # initialize soup object to parse html data\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # get the name of the coach\n",
    "    name = soup.find(id='meta').find('h1').text.strip()\n",
    "\n",
    "    # dob\n",
    "    dob = soup.find(id=\"necro-birth\").text.strip()\n",
    "    dob_obj = datetime.strptime(dob, \"%B %d, %Y\")\n",
    "    dob = str(dob_obj).split(' ')[0]\n",
    "\n",
    "    coach_df.loc[coach_df.shape[0]] = [name, dob, team_name]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change type of dob to datetime64\n",
    "coach_df['Date of Birth'] = pd.to_datetime(coach_df['Date of Birth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory \"csv_files\" cannot be created\n"
     ]
    }
   ],
   "source": [
    "# adjust indexing on current data frame\n",
    "coach_df.index += 1\n",
    "\n",
    "# save it to a csv file\n",
    "\n",
    "# create directory\n",
    "dir_name = 'csv_files'\n",
    "\n",
    "try:\n",
    "    os.makedirs(dir_name)\n",
    "except OSError as error:\n",
    "    print(f'Directory \"{dir_name}\" cannot be created')\n",
    "\n",
    "coach_df.to_csv('csv_files/coaches.csv', header=coach_df.columns, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                object\n",
       "Abbreviated Name    object\n",
       "Arena               object\n",
       "Wins                 int64\n",
       "Losses               int64\n",
       "W-L                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here to check the types of the fields in the dataframes\n",
    "teams_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Field Goals                      float64\n",
       "Field Goals Attempted            float64\n",
       "Field Goal %                     float64\n",
       "3-Point Field Goals              float64\n",
       "3-Point Field Goals Attempted    float64\n",
       "3-Point Field Goal %             float64\n",
       "2-Point Field Goals              float64\n",
       "2-Point Field Goals Attempted    float64\n",
       "2-Point Field Goal %             float64\n",
       "Free Throws                      float64\n",
       "Free Throws Attempted            float64\n",
       "Free Throw %                     float64\n",
       "Offensive Rebounds               float64\n",
       "Defensive Rebounds               float64\n",
       "Total Rebounds                   float64\n",
       "Assists                          float64\n",
       "Steals                           float64\n",
       "Blocks                           float64\n",
       "Turnovers                        float64\n",
       "Personal Fouls                   float64\n",
       "Points                           float64\n",
       "Name                              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams_stats_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                     object\n",
       "Date of Birth    datetime64[ns]\n",
       "Position                 object\n",
       "Team                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                              object\n",
       "Minutes Played                   float64\n",
       "Field Goals                      float64\n",
       "Field Goals Attempted            float64\n",
       "Field Goal %                     float64\n",
       "3-Point Field Goals              float64\n",
       "3-Point Field Goals Attempted    float64\n",
       "3-Point Field Goal %             float64\n",
       "2-Point Field Goals              float64\n",
       "2-Point Field Goals Attempted    float64\n",
       "2-Point Field Goal %             float64\n",
       "Effective Field Goal %           float64\n",
       "Free Throws                      float64\n",
       "Free Throws Attempted            float64\n",
       "Free Throw %                     float64\n",
       "Offensive Rebounds               float64\n",
       "Defensive Rebounds               float64\n",
       "Total Rebounds                   float64\n",
       "Assists                          float64\n",
       "Steals                           float64\n",
       "Blocks                           float64\n",
       "Turnovers                        float64\n",
       "Personal Fouls                   float64\n",
       "Points                           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players_stats_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                     object\n",
       "Date of Birth    datetime64[ns]\n",
       "Team                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coach_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data collected and saved to csv files under 'csv_files'\n",
    "- now write script to create database tables, read data from csv files and insert to database (file is 'nba_script.py')\n",
    "- filter/clean any data that might need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert pandas data types to database data types\n",
    "# pandas data type: postgres data type\n",
    "type_replacements = {\n",
    "    'object': 'varchar',\n",
    "    'float64': 'float',\n",
    "    'int64': 'int',\n",
    "    'datetime64[ns]': 'timestamp',\n",
    "    'timedelta64[ns]': 'varchar'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean table names i.e., spaces replaced with underscore\n",
    "dfs = [teams_df, teams_stats_df, players_df, players_stats_df, coach_df]\n",
    "\n",
    "for df in dfs:\n",
    "    df.columns = df.columns.str.replace(' ', \"_\").str.replace(\"-\", \"_\").str.replace(\"%\", \"Pct\").str.replace(\"2\", \"Two\").str.replace(\"3\", \"Three\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'teams': 'Name varchar, Abbreviated_Name varchar, Arena varchar, Wins int, Losses int, W_L varchar',\n",
       " 'teams_stats': 'Field_Goals float, Field_Goals_Attempted float, Field_Goal_Pct float, Three_Point_Field_Goals float, Three_Point_Field_Goals_Attempted float, Three_Point_Field_Goal_Pct float, Two_Point_Field_Goals float, Two_Point_Field_Goals_Attempted float, Two_Point_Field_Goal_Pct float, Free_Throws float, Free_Throws_Attempted float, Free_Throw_Pct float, Offensive_Rebounds float, Defensive_Rebounds float, Total_Rebounds float, Assists float, Steals float, Blocks float, Turnovers float, Personal_Fouls float, Points float, Name varchar',\n",
       " 'players': 'Name varchar, Date_of_Birth timestamp, Position varchar, Team varchar',\n",
       " 'players_stats': 'Name varchar, Minutes_Played float, Field_Goals float, Field_Goals_Attempted float, Field_Goal_Pct float, Three_Point_Field_Goals float, Three_Point_Field_Goals_Attempted float, Three_Point_Field_Goal_Pct float, Two_Point_Field_Goals float, Two_Point_Field_Goals_Attempted float, Two_Point_Field_Goal_Pct float, Effective_Field_Goal_Pct float, Free_Throws float, Free_Throws_Attempted float, Free_Throw_Pct float, Offensive_Rebounds float, Defensive_Rebounds float, Total_Rebounds float, Assists float, Steals float, Blocks float, Turnovers float, Personal_Fouls float, Points float',\n",
       " 'coaches': 'Name varchar, Date_of_Birth timestamp, Team varchar'}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop through every column in the data frame, and append the postgres matching data type\n",
    "# i.e., 'Name varchar, Wins int' to be used for create table statement\n",
    "\n",
    "# teams_df.dtypes.replace(type_replacements) replaces the pandas types with our dictionary type mappings\n",
    "# column_names = \", \".join([c, t for c, t in zip()])\n",
    "\n",
    "# mapping df to string rep\n",
    "dfs_dict = {\n",
    "    str(teams_df): 'teams',\n",
    "    str(teams_stats_df): 'teams_stats',\n",
    "    str(players_df): 'players',\n",
    "    str(players_stats_df): 'players_stats',\n",
    "    str(coach_df): 'coaches'\n",
    "}\n",
    "\n",
    "table_create_strings = {}\n",
    "\n",
    "for df in dfs:\n",
    "    col_types_strings = []\n",
    "    \n",
    "    # for each data frame, assemble the create table inner string for each\n",
    "    for (c, t) in zip(df.columns, df.dtypes.replace(type_replacements)):\n",
    "        col_types_strings.append(f'{c} {t}')\n",
    "        column_string = \", \".join(col_types_strings)\n",
    "    \n",
    "    # save it in the strings dictionary\n",
    "    table_create_strings[dfs_dict[str(df)]] = column_string\n",
    "\n",
    "table_create_strings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file copied to db\n",
      "teams imported to db completed\n",
      "file copied to db\n",
      "teams_stats imported to db completed\n",
      "file copied to db\n",
      "players imported to db completed\n",
      "file copied to db\n",
      "players_stats imported to db completed\n",
      "file copied to db\n",
      "coaches imported to db completed\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# open a database connection\n",
    "conn = None\n",
    "cur = None\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\", \n",
    "        dbname=f\"{os.getenv('POSTGRES_DB')}\", \n",
    "        user=f\"{os.getenv('POSTGRES_USER')}\", \n",
    "        password=f\"{os.getenv('POSTGRES_PASSWORD')}\", \n",
    "        port=f\"{os.getenv('POSTGRES_PORT')}\"\n",
    "    )\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    for table, exec_string in table_create_strings.items():\n",
    "        # drop tables with the same name to avoid conflict\n",
    "        cur.execute(f\"drop table if exists {table};\")\n",
    "    \n",
    "        # create table\n",
    "        cur.execute(f\"create table {table} ({exec_string});\")\n",
    "    \n",
    "        # insert values to table\n",
    "        # save df to csv if not done\n",
    "        \n",
    "        # open csv file, save it as an object, and upload to db\n",
    "        with open(f'csv_files/{table}.csv', encoding=\"cp437\", errors='ignore') as file_obj:\n",
    "            sql_statement = f\"\"\"\n",
    "                COPY {table} FROM STDIN WITH\n",
    "                    CSV\n",
    "                    HEADER\n",
    "                    DELIMITER AS ','\n",
    "            \"\"\"\n",
    "            \n",
    "            cur.copy_expert(sql=sql_statement, file=file_obj)\n",
    "            print('file copied to db')\n",
    "            \n",
    "            # grant public access on table\n",
    "            cur.execute(f\"grant select on table {table} to public\")\n",
    "            conn.commit()\n",
    "            \n",
    "            print(f'{table} imported to db completed')\n",
    "    \n",
    "    \n",
    "except Exception as error:\n",
    "    print(error)\n",
    "finally:\n",
    "    if cur is not None:\n",
    "        cur.close()\n",
    "    if conn is not None:\n",
    "        conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6184136c414f2ed1c234f4dbd1a92b7a98a1510cf556a32e9118757207ffca48"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
